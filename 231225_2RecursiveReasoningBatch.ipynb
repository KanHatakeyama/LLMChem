{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#再帰的に構造ー物性相関データセットから理由を生成させる\n",
    "#バッチ処理\n",
    "\n",
    "#ライブラリの自動インポート\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "openai.api_key =os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'mpC': 152.0,\n",
       "  'name': '3-phthalimidopropionic acid',\n",
       "  'smiles': 'c1ccc2c(c1)C(=O)N(C2=O)CCC(=O)O',\n",
       "  'csid': 69310,\n",
       "  'link': 'http://www.alfa.com/en/GP100W.pgm?DSSTK=L13535',\n",
       "  'source': 'Alfa Aesar'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#laod dataset as dict\n",
    "csv_path=\"dataset/BradleyMeltingPointDataset_practice.csv\"\n",
    "df=pd.read_csv(csv_path)\n",
    "chemical_records=df.to_dict(orient='records')\n",
    "chemical_records[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=\"gpt-4-1106-preview\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt=\"\"\"\n",
    "Provide the quantitative Reason and Prediction so that a scientist, who does not know the melting point, can predict the value.\n",
    "\n",
    "#Commands\n",
    "- You must quantitatively consider how the melting point shifts, focusing on each functional groups.\n",
    "- Actual value and Prediction must match each other.\n",
    "- If Actual value and Prediction differ each other, rethink Reason.\n",
    "- If Prediction does not contain numbers for each functional group effect, rethink Reason\n",
    "\n",
    "#Example reason\n",
    "- Target compound: Toluene\n",
    "- Basic unit, benzene has a boiling point of 80.\n",
    "- Methyl group: +30 (due to larger molecular weight)\n",
    "- Prediction: 110\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_prompt(chemical_record,reason=\"\",prediction=\"\"):\n",
    "    name=chemical_record[\"name\"]\n",
    "    smiles=chemical_record[\"smiles\"]\n",
    "    value=chemical_record[\"mpC\"]\n",
    "    prompt=f\"\"\"\n",
    "#Data\n",
    "-Name: {name}\n",
    "-SMILES: {smiles} \n",
    "-Actual value: {value}\n",
    "-Reason: {reason}\n",
    "-Prediction: {prediction}\n",
    "\n",
    "#Output (JSON keys)\n",
    "- Reason, Prediction\n",
    "\"\"\"\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "#ask gpt\n",
    "def json_generate(prompt,model=\"gpt-3.5-turbo-1106\"):\n",
    "    response = openai.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt,\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"{prompt}\"\"\"\n",
    "        }  \n",
    "    ],\n",
    "    response_format={ \"type\": \"json_object\" }\n",
    "    )\n",
    "\n",
    "    return (json.loads(response.choices[0].message.content))\n",
    "\n",
    "\n",
    "#parse prediction\n",
    "def prediction_string_to_number(prompt,model=\"gpt-3.5-turbo-1106\"):\n",
    "    response = openai.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"Extract integer from prediction. Use average if multiple numbers are included.\n",
    "            Examples:\n",
    "            In: 70.2 - 75.2 degrees Celsius\n",
    "            Out: 73\n",
    "            In: 75.2 degrees Celsius\n",
    "            Out: 73\n",
    "            In: For 1-naphthalenecarboxaldehyde, starting with the base value for naphthalene with a melting point of 80\\u00b0C and subtracting the estimated aldehyde effect of approximately -47 to -50\\u00b0C, the predicted melting point would be in the range of 30-33\\u00b0C.\n",
    "            Out: 32\n",
    "            \"\"\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"{prompt}\n",
    "\"#Output (JSON keys)\n",
    "- Prediction\"\"\"\n",
    "        }  \n",
    "    ],\n",
    "    response_format={ \"type\": \"json_object\" }\n",
    "    )\n",
    "\n",
    "    return (json.loads(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t=prediction_string_to_number(\"Considering a starting point of 80\\u00b0C for naphthalene and accounting for the influence of the aldehyde functional group, which can reduce the melting point by 47 to 50\\u00b0C, the estimated melting point for 1-naphthalenecarboxaldehyde is around 30 to 33\\u00b0C, closely aligning with the actual value of 33.5\\u00b0C.\")\n",
    "#t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "save_base_path=\"dataset/231225AutoReasoning/\"\n",
    "\n",
    "\n",
    "#load finished records\n",
    "gen_records={}\n",
    "gen_json_path_list=glob.glob(save_base_path+\"*.json\")\n",
    "for gen_json_path in tqdm(gen_json_path_list):\n",
    "    with open(gen_json_path) as f:\n",
    "        gen_record=json.load(f)\n",
    "    gen_records[gen_record[\"name\"]]=gen_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_non_alphabet_characters(s):\n",
    "    # Using regex to remove all non-alphabet characters\n",
    "    return re.sub('[^a-zA-Z]', '', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_recursion=2\n",
    "n_random_repeat=3\n",
    "error_threshold=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip because already generated: 3-phthalimidopropionic acid\n",
      "Skip because already generated: 1-naphthalenecarboxaldehyde\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [01:57<02:58, 29.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished because good reasoning was achieved: tetradecanoyl chloride\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [02:44<02:56, 35.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished because good reasoning was achieved: indopan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [02:56<01:52, 28.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished because good reasoning was achieved: 2-[3-(4-ethoxyphenyl)-5,6-dihydro[1,2,4]triazolo[3,4-b][1,3,4]thiadiazol-6-yl]phenol\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [03:47<01:45, 35.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished because good reasoning was achieved: ethanol, 2-[(2-amino-9h-purin-9-yl)methoxy]-\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [04:34<01:17, 38.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished because good reasoning was achieved: (1E)-1-(1,2-dihydroacenaphthylen-5-yl)-N-hydroxy-2-phenylethanimine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [07:15<00:00, 43.53s/it]\n"
     ]
    }
   ],
   "source": [
    "#batch \n",
    "for chemical_record in tqdm(chemical_records):\n",
    "\n",
    "    #load record\n",
    "    gen_record=copy.deepcopy(chemical_record)\n",
    "\n",
    "    #skip if already generated\n",
    "    if gen_record[\"name\"] in gen_records:\n",
    "        print(f\"Skip because already generated: {gen_record['name']}\")\n",
    "        continue\n",
    "\n",
    "    record_history=[]\n",
    "\n",
    "    fin_flag=False\n",
    "    #make suggestion with random seed\n",
    "    for j in range(n_random_repeat):\n",
    "        if fin_flag:\n",
    "            break\n",
    "\n",
    "        gen_record[\"Reason\"]=\"\"\n",
    "        gen_record[\"Prediction\"]=\"\"\n",
    "        if j==0:\n",
    "            record_history.append(copy.deepcopy(gen_record))\n",
    "\n",
    "        #improve reasoing\n",
    "        for i in range(n_recursion):\n",
    "            r=json_generate(\n",
    "                gen_prompt(gen_record,\n",
    "                        reason=gen_record[\"Reason\"],\n",
    "                        prediction=gen_record[\"Prediction\"]\n",
    "                ),\n",
    "                model=model,\n",
    "            )\n",
    "            #parse prediction string to number\n",
    "            gen_record.update(r)\n",
    "            try:\n",
    "                gen_record[\"Prediction(integer)\"]=float(prediction_string_to_number(gen_record[\"Prediction\"])[\"Prediction\"])\n",
    "            except:\n",
    "                gen_record[\"Prediction(integer)\"]=99999\n",
    "            record_history.append(copy.deepcopy(gen_record))\n",
    "            \n",
    "            #finish reasoning if prediction is close to actual value\n",
    "            if abs(gen_record[\"Prediction(integer)\"]-gen_record[\"mpC\"])<=error_threshold:\n",
    "                fin_flag=True\n",
    "                print(f\"Finished because good reasoning was achieved: {gen_record['name']}\")\n",
    "                break\n",
    "\n",
    "    #save\n",
    "    save_name=remove_non_alphabet_characters(gen_record[\"name\"])\n",
    "    save_path=save_base_path+f\"{save_name}.json\"\n",
    "    with open(save_path, 'w') as f:\n",
    "        json.dump(record_history, f, indent=4)\n",
    "\n",
    "    gen_records[gen_record[\"name\"]]=record_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tokens: 298\n",
      "Output tokens: 205\n",
      "Cost: 0.01826 USD\n",
      "Cost: 2.739 JP\n"
     ]
    }
   ],
   "source": [
    "#値段の概算\n",
    "t=gen_prompt(gen_record,\n",
    "               reason=gen_record[\"Reason\"],\n",
    "               prediction=gen_record[\"Prediction\"]\n",
    "    )\n",
    "user_len=len(t.split(\" \"))\n",
    "system_len=len(system_prompt.split(\" \"))\n",
    "\n",
    "input_cost=0.01/1000*(user_len+system_len)\n",
    "\n",
    "gen_len=len(gen_record[\"Reason\"].split(\" \"))+len(gen_record[\"Prediction\"].split(\" \"))\n",
    "output_cost=0.03/1000*gen_len\n",
    "\n",
    "n_trials=2\n",
    "cost=n_trials*(input_cost+output_cost)\n",
    "print(f\"Input tokens: {user_len+system_len}\")\n",
    "print(f\"Output tokens: {gen_len}\")\n",
    "print(f\"Cost: {cost} USD\")\n",
    "print(f\"Cost: {cost*150} JP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
