{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/setup/miniconda3/envs/chemllm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "import random\n",
    "import copy\n",
    "from llmchem.utils import  make_project_dirs\n",
    "from llmchem.eval import eval_model\n",
    "\n",
    "# dataset settings\n",
    "n_test = 50  # number of testing data\n",
    "# number of training data for checking (i.e., checking everything takes too long, so we check only a part of training data)\n",
    "n_train_check = 50\n",
    "\n",
    "n_prompt_examples = 5\n",
    "\n",
    "# dataset path\n",
    "dataset_path = \"dataset/231225AutoReasoning/240117best_reason_record_11k.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial----\n",
      "model gpt-3.5-turbo-1106 reason: False\n",
      "Task : results/projects/240118comparisons_wo_reason/GPT-3.5-turbo_3_32_0\n",
      "test exists: results/projects/240118comparisons_wo_reason/GPT-3.5-turbo_3_32_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "promlem 1 / 5\n",
      "----\n",
      "\n",
      "\n",
      "##Reason: The molecule contains functional groups that can participate in various chemical reactions, leading to potential biological activity.\n"
     ]
    }
   ],
   "source": [
    "#evaluation w/o training\n",
    "\n",
    "# %%\n",
    "model_dict = {\n",
    "    \"GPT-3.5-turbo\": {\n",
    "        \"name\": \"gpt-3.5-turbo-1106\",\n",
    "        \"modules\": [\n",
    "        ]\n",
    "    },\n",
    "    \"GPT-4-turbo\":{\n",
    "    \"name\":\"gpt-4-1106-preview\",\n",
    "    \"modules\":[]\n",
    "    },\n",
    "    \"GPT-3.5-turbo-FT10\":{\n",
    "    \"name\":\"ft:gpt-3.5-turbo-1106:personal::8kicrQm5\",\n",
    "    \"modules\":[]\n",
    "    },\n",
    "    \"GPT-3.5-turbo-FT20\":{\n",
    "    \"name\":\"ft:gpt-3.5-turbo-1106:personal::8kiw9gBe\",\n",
    "    \"modules\":[]\n",
    "    },\n",
    "    \"GPT-3.5-turbo-FT50\":{\n",
    "    \"name\":\"ft:gpt-3.5-turbo-1106:personal::8kiwu9s0\",\n",
    "    \"modules\":[]\n",
    "    },\n",
    "    \"GPT-3.5-turbo-FT100\":{\n",
    "    \"name\":\"ft:gpt-3.5-turbo-1106:personal::8kj2LEBW\",\n",
    "    \"modules\":[]\n",
    "    },\n",
    "    \"GPT-3.5-turbo-FT1000\":{\n",
    "    \"name\":\"\",\n",
    "    \"modules\":[]\n",
    "    },\n",
    "    \"GPT-3.5-turbo-FT2000\":{\n",
    "    \"name\":\"\",\n",
    "    \"modules\":[]\n",
    "    },\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "#dummy values\n",
    "epochs=3\n",
    "r=32\n",
    "n_train=0\n",
    "\n",
    "for model_nickname in model_dict:\n",
    "    model_name = model_dict[model_nickname][\"name\"]\n",
    "    if model_name==\"\":\n",
    "        continue\n",
    "\n",
    "    if model_nickname.find(\"FT\") >= 0:\n",
    "        n_train = int(model_nickname.split(\"FT\")[-1])\n",
    "        model_nickname_=\"GPT-3.5-turbo\"\n",
    "    else:\n",
    "        model_nickname_=model_nickname\n",
    "        n_train=0\n",
    "    \n",
    "\n",
    "    for with_reason in [False, True]:\n",
    "        print(\"trial----\")\n",
    "        print(f\"model {model_name} reason: {with_reason}\")\n",
    "        # project path\n",
    "        if with_reason:\n",
    "            project_dir = f\"results/projects/240118comparisons/{model_nickname_}_{epochs}_{r}_{n_train}\"\n",
    "        else:\n",
    "            project_dir = f\"results/projects/240118comparisons_wo_reason/{model_nickname_}_{epochs}_{r}_{n_train}\"\n",
    "        print(\"Task :\", project_dir)\n",
    "\n",
    "\n",
    "        # make project dir\n",
    "        make_project_dirs(project_dir)\n",
    "\n",
    "        # load dataset\n",
    "        dataset = df.to_dict(orient=\"records\")\n",
    "        random.seed(0)\n",
    "        random.shuffle(dataset)\n",
    "\n",
    "        # prediction without reason\n",
    "        if not with_reason:\n",
    "            for data in dataset:\n",
    "                data[\"Reason\"] = \"-\"\n",
    "\n",
    "        train_dataset = dataset[:max(n_train, n_prompt_examples)]\n",
    "        test_dataset = dataset[-n_test:]\n",
    "\n",
    "        random.shuffle(train_dataset)\n",
    "        # eval\n",
    "        train_check_dataset = copy.deepcopy(\n",
    "            train_dataset[:n_train_check])\n",
    "        random.shuffle(train_check_dataset)\n",
    "        model=model_name\n",
    "        tokenizer=None\n",
    "        if len(glob.glob(f\"{project_dir}/eval/test*\")) > 0:\n",
    "            print(f\"test exists: {project_dir}\")\n",
    "        else:\n",
    "            test_eval_result = eval_model(model, tokenizer, test_dataset,\n",
    "                                            f\"{project_dir}/eval\",\n",
    "                                            n_prompt_examples=n_prompt_examples,\n",
    "                                            prefix=f\"test\",\n",
    "                                            gpt_mode=True,\n",
    "                                            n_max_trials=3\n",
    "                                            )\n",
    "        if len(glob.glob(f\"{project_dir}/eval/train*\")) > 0:\n",
    "            print(f\"train exists: {project_dir}\")\n",
    "        else:\n",
    "            if n_train>0:\n",
    "                train_eval_result = eval_model(model, tokenizer, train_check_dataset,\n",
    "                                        f\"{project_dir}/eval\",\n",
    "                                        n_prompt_examples=n_prompt_examples,\n",
    "                                        prefix=f\"train\",\n",
    "                                        gpt_mode=True,\n",
    "                                        n_max_trials=3\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmchem.dataset import generate_question_prompt,gen_train_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# JSONL形式でファイルに書き出す\n",
    "ft_text_base_dir=\"results/projects/240125gpt3_train_text\"\n",
    "for n_train in [ 5, 10, 20, 50, 100, 1000, 2000, 5000, 10000]:\n",
    "    for with_reason in [False, True]:\n",
    "        # load dataset\n",
    "        dataset = df.to_dict(orient=\"records\")\n",
    "        random.seed(0)\n",
    "        random.shuffle(dataset)\n",
    "\n",
    "        # prediction without reason\n",
    "        if not with_reason:\n",
    "            for data in dataset:\n",
    "                data[\"Reason\"] = \"-\"\n",
    "\n",
    "        train_dataset = dataset[:max(n_train, n_prompt_examples)]\n",
    "        test_dataset = dataset[-n_test:]\n",
    "\n",
    "        random.shuffle(train_dataset)\n",
    "        train_json_list=[]\n",
    "        for train_id in range(len(train_dataset)):\n",
    "            question = generate_question_prompt(\n",
    "                train_dataset, train_id, n_prompt_examples=0).strip()\n",
    "\n",
    "            answer=f\"\"\" {train_dataset[train_id][\"Reason\"]}\n",
    "##Prediction: {train_dataset[train_id][\"Prediction(integer)\"]}\"\"\"\n",
    "            json_data={\"messages\": [\n",
    "                {\"role\": \"system\", \"content\":\"You are a professional chemist, who only output ##Reason and ##Prediction. Complete the text. Never output anything else.\"},\n",
    "                {\"role\": \"user\", \"content\": question},\n",
    "                                        {\"role\": \"assistant\", \"content\": answer}]}\n",
    "\n",
    "            train_json_list.append(json_data)\n",
    "        with open(f\"{ft_text_base_dir}/ft{n_train}.jsonl\", 'w') as file:\n",
    "            for data in train_json_list:\n",
    "                json_data = json.dumps(data)\n",
    "                file.write(json_data + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
